"""
ë³´ì¡´ë ¥ ì‹œí—˜ OCR ë°±ì—”ë“œ ë¡œì§
Streamlitì—ì„œ ì§ì ‘ importí•˜ì—¬ ì‚¬ìš©
"""

import io
import re
import fitz
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from openpyxl import Workbook
import os
import logging
import math
from typing import List, Dict, Tuple, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

from dotenv import load_dotenv
load_dotenv()
# ì„¤ì •
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
UPSTAGE_URL = "https://api.upstage.ai/v1/document-ai/document-parse"
STRAINS = ['E.coli', 'P.aeruginosa', 'S.aureus', 'C.albicans', 'A.brasiliensis']


class PDFProcessor:
    """PDF ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def extract_page_count(pdf_bytes: bytes) -> int:
        """PDF í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ"""
        try:
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            return doc.page_count
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 0
    
    @staticmethod
    def render_page_image(pdf_bytes: bytes, page_index: int, zoom: float = 2.0) -> bytes:
        """PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë Œë”ë§"""
        try:
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            page = doc.load_page(page_index)
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat, alpha=False)
            return pix.tobytes("png")
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë Œë”ë§ ì‹¤íŒ¨: {e}")
            return None


class OCRProcessor:
    """OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def request_ocr(image_bytes: bytes) -> Optional[dict]:
        """ì—…ìŠ¤í…Œì´ì§€ OCR API í˜¸ì¶œ"""
        try:
            headers = {"Authorization": f"Bearer {UPSTAGE_API_KEY}"}
            files = {"document": ("image.jpg", image_bytes, "image/jpeg")}
            data = {
                "model": "document-parse",
                "ocr": "force",
                "base64_encoding": "['table']"
            }
            
            response = requests.post(
                UPSTAGE_URL, 
                headers=headers, 
                files=files, 
                data=data, 
                timeout=120
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"OCR API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"OCR ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def parse_table_from_ocr(ocr_result: dict) -> Tuple[List[dict], dict]:
        """OCR ê²°ê³¼ì—ì„œ í…Œì´ë¸” íŒŒì‹±"""
        try:
            html_parts = []
            if 'elements' in ocr_result:
                for element in ocr_result.get("elements", []):
                    content = element.get("content", {})
                    html = content.get("html", "")
                    if html:
                        html_parts.append(html)
            
            if not html_parts:
                return [], {}
            
            html_content = "<html><body>\n" + "\n".join(html_parts) + "\n</body></html>"
            soup = BeautifulSoup(html_content, 'html.parser')
            table = soup.find('table')
            
            if not table:
                return [], {}
            
            rows = table.find_all('tr')
            if len(rows) < 3:
                return [], {}
            
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_info = DataCleaner.extract_date_info(rows)
            
            # í…Œì´ë¸” ë°ì´í„° íŒŒì‹±
            table_data = DataCleaner.parse_table_rows(rows)
            
            return table_data, date_info
            
        except Exception as e:
            logger.error(f"í…Œì´ë¸” íŒŒì‹± ì˜¤ë¥˜: {e}")
            return [], {}


class DataCleaner:
    """ë°ì´í„° ì •ì œ í´ë˜ìŠ¤"""
    
    @staticmethod
    def extract_date_info(rows) -> dict:
        """
        ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (ê°œì„  ë²„ì „)
        
        ê°œì„  ì‚¬í•­:
        - ì—°ì†ëœ ë‚ ì§œ ë¬¸ìì—´ ì§€ì› ì¶”ê°€
        - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        """
        date_info = {}
        if len(rows) >= 2:
            header_cells = rows[1].find_all('td')
            if len(header_cells) >= 1:
                first_date_str = header_cells[0].text.strip()
                
                # ğŸ†• ì—°ì† ë‚ ì§œ íŒ¨í„´ ë¨¼ì € ì‹œë„
                consecutive_dates = DataCleaner.parse_consecutive_dates(first_date_str)
                if consecutive_dates and len(consecutive_dates) >= 4:
                    date_info = {
                        'date_0': consecutive_dates[0],
                        'date_7': consecutive_dates[1],
                        'date_14': consecutive_dates[2],
                        'date_28': consecutive_dates[3]
                    }
                    return date_info
                
                # ê¸°ì¡´ ë°©ì‹ (ë‹¨ì¼ ë‚ ì§œ íŒŒì‹±)
                first_date = DataCleaner.parse_date(first_date_str)
                
                if first_date:
                    date_info = {
                        'date_0': first_date.strftime("%m/%d"),
                        'date_7': (first_date + timedelta(days=7)).strftime("%m/%d"),
                        'date_14': (first_date + timedelta(days=14)).strftime("%m/%d"),
                        'date_28': (first_date + timedelta(days=28)).strftime("%m/%d")
                    }
        return date_info
    
    @staticmethod
    def parse_table_rows(rows) -> List[dict]:
        """í…Œì´ë¸” í–‰ íŒŒì‹±"""
        table_data = []
        current_test_number = None
        current_prescription_number = None
        
        for i, row in enumerate(rows[2:], start=3):
            cells = row.find_all('td')
            if len(cells) < 2:
                continue
            
            # Bulk Name í–‰ ê°ì§€
            if cells[0].get('rowspan') and cells[0].text.strip():
                bulk_name = cells[0].text.strip()
                current_test_number, current_prescription_number = DataCleaner.extract_numbers(bulk_name)
                
                if len(cells) > 1:
                    strain = cells[1].text.strip()
                    cfu_indices = {'0ì¼': 3, '7ì¼': 4, '14ì¼': 5, '28ì¼': 6, 'íŒì •': 7, 'ìµœì¢…íŒì •': 8}
                else:
                    continue
            else:
                if len(cells) < 1:
                    continue
                strain = cells[0].text.strip()
                cfu_indices = {'0ì¼': 2, '7ì¼': 3, '14ì¼': 4, '28ì¼': 5, 'íŒì •': 6, 'ìµœì¢…íŒì •': 7}
            
            # ìœ íš¨í•œ ê· ì£¼ í™•ì¸
            valid_strains = STRAINS + ['Escherichia', 'Pseudomonas', 'Staphylococcus', 'Candida', 'Aspergillus']
            if not strain or not any(valid_strain in strain for valid_strain in valid_strains):
                continue
            
            strain_normalized = DataCleaner.normalize_strain_name(strain)
            
            # CFU ë°ì´í„° ì¶”ì¶œ
            row_data = {
                'test_number': current_test_number or '',
                'prescription_number': current_prescription_number or '',
                'strain': strain_normalized,
                'cfu_0day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['0ì¼']].text.strip() if len(cells) > cfu_indices['0ì¼'] else "", 
                    strain_normalized, '0ì¼'
                ),
                'cfu_7day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['7ì¼']].text.strip() if len(cells) > cfu_indices['7ì¼'] else "", 
                    strain_normalized, '7ì¼'
                ),
                'cfu_14day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['14ì¼']].text.strip() if len(cells) > cfu_indices['14ì¼'] else "", 
                    strain_normalized, '14ì¼'
                ),
                'cfu_28day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['28ì¼']].text.strip() if len(cells) > cfu_indices['28ì¼'] else "", 
                    strain_normalized, '28ì¼'
                ),
                'judgment': DataCleaner.get_judgment_value(cells, cfu_indices),
                'final_judgment': DataCleaner.get_final_judgment_value(cells, cfu_indices)
            }
            
            if any(v for k, v in row_data.items() if k.startswith('cfu_') and v.strip()):
                table_data.append(row_data)
        
        return table_data
    
    @staticmethod
    def extract_numbers(bulk_name: str) -> Tuple[Optional[str], Optional[str]]:
        """
        ì‹œí—˜ë²ˆí˜¸ì™€ ì²˜ë°©ë²ˆí˜¸ ì¶”ì¶œ (ê°œì„  ë²„ì „)
        
        ê°œì„  ì‚¬í•­:
        - A-L ë²”ìœ„ë¡œ í™•ì¥ (ê¸°ì¡´: A-Z)
        - I/1 OCR ì˜¤ë¥˜ ìë™ ë³´ì •
        - ë” ë§ì€ ì²˜ë°©ë²ˆí˜¸ íŒ¨í„´ ì§€ì›
        - ê³µë°± ì²˜ë¦¬ ê°•í™”
        """
        test_number = None
        prescription_number = None
        
        try:
            # ì „ì²˜ë¦¬
            bulk_name = bulk_name.upper()
            bulk_name = bulk_name.replace('!', 'I')  # OCR ì˜¤ë¥˜ ë³´ì •
            bulk_name = re.sub(r'-\s+', '-', bulk_name)  # '- ' â†’ '-'
            bulk_name = re.sub(r'\s+', ' ', bulk_name)   # ì—°ì† ê³µë°± ì œê±°
            
            # ======== ì²˜ë°©ë²ˆí˜¸ íŒ¨í„´ (í™•ì¥) ========
            prescription_patterns = [
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,5}\d?\b',
                r'\b[A-Z]{3}\d{5}-[A-Z]{2,4}\b',
                r'\b[A-Z]{2,4}\d{3,6}-[A-Z]{1,5}\b',
                r'\b[A-Z]{2,5}\d{4}-[A-Z]{1,3}\d{0,2}\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-\s*[A-Z]{1,5}\d?\b',  # ê³µë°± í—ˆìš©
                r'\b[A-Z]{2,4}\d{3,5}-[A-Z]{1,4}\d{1,2}\b',  # AZLY1 íƒ€ì…
            ]
            
            all_prescription_matches = []
            for pattern in prescription_patterns:
                matches = re.findall(pattern, bulk_name)
                all_prescription_matches.extend(matches)
            
            # ======== ì‹œí—˜ë²ˆí˜¸ íŒ¨í„´ (A-L í™•ì¥ + OCR ë³´ì •) ========
            all_test_matches = []
            
            # ì •ìƒ í˜•íƒœ (Iê°€ ì •í™•íˆ ì¸ì‹ëœ ê²½ìš°)
            correct_matches = re.findall(r'\b(\d{2}[A-L]\d{2}I\d{2,3})\b', bulk_name)
            all_test_matches.extend(correct_matches)
            
            # OCR ì˜¤ë¥˜ í˜•íƒœ (Ië¥¼ 1ë¡œ ì˜ëª» ì¸ì‹)
            ocr_error_patterns = [
                r'\b(\d{2}[A-L]\d{2}1\d{2,3})\b',   # Iê°€ 1ë¡œ
                r'\b(\d{2}[A-L]\d{5,6})\b',         # I ëˆ„ë½
            ]
            
            for pattern in ocr_error_patterns:
                matches = re.findall(pattern, bulk_name)
                for match in matches:
                    if len(match) == 7:  # 25A2012 â†’ 25A20I2
                        corrected = match[:5] + 'I' + match[6:]
                        all_test_matches.append(corrected)
                        logger.info(f"OCR I/1 ë³´ì •: '{match}' â†’ '{corrected}'")
                    elif len(match) == 8:  # 25A20102 â†’ 25A20I02
                        corrected = match[:5] + 'I' + match[6:]
                        all_test_matches.append(corrected)
                        logger.info(f"OCR I ì‚½ì… ë³´ì •: '{match}' â†’ '{corrected}'")
            
            # ê³µë°±ì´ ìˆëŠ” í˜•íƒœ (A-L í™•ì¥)
            raw_matches = re.findall(r'(\d{2})([A-L])(\d)\s+(\d)(\d{2,3})', bulk_name)
            for year_prefix, letter, d1, d2, last_digits in raw_matches:
                converted = f"{year_prefix}{letter}{d1}{d2}I{last_digits[:2]}"
                all_test_matches.append(converted)
            
            # ì¤‘ë³µ ì œê±°
            all_test_matches = list(dict.fromkeys(all_test_matches))
            all_prescription_matches = list(dict.fromkeys(all_prescription_matches))
            
            test_number = all_test_matches[0] if all_test_matches else None
            prescription_number = all_prescription_matches[0] if all_prescription_matches else None
            
            return test_number, prescription_number
            
        except Exception as e:
            logger.warning(f"ë²ˆí˜¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None
    
    @staticmethod
    def normalize_strain_name(strain: str) -> str:
        """ê· ì£¼ëª… ì •ê·œí™”"""
        strain_mapping = {
            'E.coli': 'E.coli', 'Escherichia coli': 'E.coli', 'E. coli': 'E.coli',
            'P.aeruginosa': 'P.aeruginosa', 'Pseudomonas aeruginosa': 'P.aeruginosa', 'P. aeruginosa': 'P.aeruginosa',
            'S.aureus': 'S.aureus', 'Staphylococcus aureus': 'S.aureus', 'S. aureus': 'S.aureus',
            'C.albicans': 'C.albicans', 'Candida albicans': 'C.albicans', 'C. albicans': 'C.albicans',
            'A.brasiliensis': 'A.brasiliensis', 'Aspergillus brasiliensis': 'A.brasiliensis', 'A. brasiliensis': 'A.brasiliensis'
        }
        
        for full_name, short_name in strain_mapping.items():
            if full_name.lower() == strain.lower():
                return short_name
        
        for full_name, short_name in strain_mapping.items():
            if full_name.lower() in strain.lower():
                return short_name
        
        return strain
    
    @staticmethod
    def clean_cfu_value(value: str, strain: str = None, day_column: str = None) -> str:
        """CFU ê°’ ì •ë¦¬ ë° ë³´ì •"""
        if not value:
            return ""
        
        original_value = value
        
        # OCR ì˜¤ë¥˜ ì œê±°
        value = re.sub(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]+', '', value)
        value = value.replace('ã', '<').replace('C', '<').replace('O', '0')
        value = value.replace('Co', '0').replace('CIO', '<10').replace('C10', '<10')
        value = value.strip()
        
        # ì§€ìˆ˜ í˜•íƒœ ì²˜ë¦¬
        if re.search(r'[Ã—xX]', value):
            exp_match = re.match(r'([0-9.]+)\s*[Ã—xX]\s*10\s*\^?([0-9]+)', value)
            if exp_match:
                base = exp_match.group(1)
                exp = exp_match.group(2)
                return f"{base}Ã—10^{exp}"
        
        # <10 í˜•íƒœ ì²˜ë¦¬
        if '<' in value:
            if re.search(r'<\s*10\s*\^?\s*([0-9]+)', value):
                exp = re.search(r'<\s*10\s*\^?\s*([0-9]+)', value).group(1)
                return f"<10^{exp}"
            elif re.search(r'<\s*([0-9]+)', value):
                return f"<{re.search(r'<\s*([0-9]+)', value).group(1)}"
            return "<10"
        
        # â‰¤ í˜•íƒœ ì²˜ë¦¬
        if 'â‰¤' in value:
            if re.search(r'â‰¤\s*([0-9]+)', value):
                num = re.search(r'â‰¤\s*([0-9]+)', value).group(1)
                return f"â‰¤{num}"
        
        # ê· ì£¼ë³„ ë³´ì •
        target_strains = ['E.coli', 'P.aeruginosa', 'S.aureus', 'C.albicans']
        is_target_strain = strain and any(s in strain for s in target_strains)
        
        if day_column in ['7ì¼', '14ì¼', '28ì¼'] and is_target_strain:
            preserve_patterns = [r'^â‰¤\d+[Â°â°]?$']
            should_preserve = any(re.match(pattern, value, re.IGNORECASE) for pattern in preserve_patterns)
            if should_preserve:
                return value
            
            if len(original_value) >= 6:
                return value
            
            if day_column == '7ì¼':
                corrected_value = "<10^2"
            elif day_column in ['14ì¼', '28ì¼']:
                corrected_value = "<10"
            else:
                corrected_value = "<10"
            
            has_clear_power_signal = ('2' in original_value and 
                                    any(char in original_value for char in ['^', 'Â²', 'â°', 'Â¹', 'Â²', 'Â³']))
            
            if has_clear_power_signal and day_column != '28ì¼':
                corrected_value = "<10^2"
            
            return corrected_value
        
        return value
    
    @staticmethod
    def get_judgment_value(cells, cfu_indices: dict) -> str:
        """íŒì • ê°’ ì¶”ì¶œ"""
        try:
            if len(cells) > cfu_indices['íŒì •']:
                raw_value = cells[cfu_indices['íŒì •']].text.strip()
                if any(char in raw_value for char in ['X', 'Ã—', 'v', 'V']):
                    return 'ë¶€ì í•©'
                return 'ì í•©'
            return "ì í•©"
        except:
            return "ì í•©"
    
    @staticmethod
    def get_final_judgment_value(cells, cfu_indices: dict) -> str:
        """ìµœì¢…íŒì • ê°’ ì¶”ì¶œ"""
        try:
            if len(cells) > cfu_indices['ìµœì¢…íŒì •']:
                raw_value = cells[cfu_indices['ìµœì¢…íŒì •']].text.strip()
                if any(char in raw_value for char in ['X', 'Ã—', 'v', 'V']):
                    return 'ë¶€ì í•©'
                return 'ì í•©'
            return "ì í•©"
        except:
            return "ì í•©"
        
    @staticmethod
    def parse_consecutive_dates(date_text: str) -> List[str]:
        """
        ì—°ì†ëœ ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±
        
        ì˜ˆì‹œ: '01 15 01 22 01 29 02 12' â†’ ['01/15', '01/22', '01/29', '02/12']
        
        Args:
            date_text (str): ì—°ì†ëœ ë‚ ì§œ ë¬¸ìì—´
            
        Returns:
            List[str]: ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ (4ê°œ)
        """
        try:
            parts = date_text.split()
            
            if len(parts) >= 8 and all(part.isdigit() and len(part) == 2 for part in parts):
                dates = []
                for i in range(0, min(8, len(parts)), 2):
                    if i + 1 < len(parts):
                        month = parts[i]
                        day = parts[i + 1]
                        dates.append(f"{month}/{day}")
                
                if len(dates) >= 4:
                    return dates[:4]
            
            return []
            
        except Exception as e:
            logger.warning(f"ì—°ì† ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
        
    @staticmethod
    def parse_date(date_str: str) -> Optional[datetime]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
        try:
            date_formats = [
                '%m %d', '%m-%d', '%m/%d', '%m.%d',
                '%mì›”%dì¼', '%mì›” %dì¼',
                '%d/%m', '%d-%m', '%d %m'
            ]
            
            for date_format in date_formats:
                try:
                    return datetime.strptime(date_str, date_format)
                except ValueError:
                    continue
            
            if re.match(r'^\d+\s+\d+$', date_str):
                try:
                    return datetime.strptime(date_str, '%m %d')
                except ValueError:
                    pass
            
            return None
        except:
            return None
    
    @staticmethod
    def convert_to_log(cfu_value: str) -> str:
        """CFU â†’ Log ë³€í™˜"""
        if not cfu_value:
            return ""
        
        try:
            if '<' in cfu_value:
                if '10^' in cfu_value:
                    exp_match = re.search(r'<10\^(\d+)', cfu_value)
                    if exp_match:
                        return f"<{exp_match.group(1)}.0"
                elif 'â‰¤' in cfu_value:
                    num_match = re.search(r'â‰¤(\d+)', cfu_value)
                    if num_match:
                        return f"<{num_match.group(1)}.0"
                return "<1.0"
            
            exp_match = re.match(r'([0-9.]+)Ã—10\^(\d+)', cfu_value)
            if exp_match:
                base = float(exp_match.group(1))
                exp = int(exp_match.group(2))
                log_value = exp + math.log10(base)
                return round(log_value, 1)
            
            try:
                num = float(cfu_value)
                return round(math.log10(num), 1)
            except ValueError:
                pass
            
            return cfu_value
            
        except Exception as e:
            logger.warning(f"Log ë³€í™˜ ì‹¤íŒ¨: {cfu_value}, ì˜¤ë¥˜: {e}")
            return cfu_value


class ExcelIncrementalSaver:
    """
    Excel ì¦ë¶„ ì €ì¥ ê´€ë¦¬ í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - í˜ì´ì§€ ì²˜ë¦¬í•  ë•Œë§ˆë‹¤ ì¦‰ì‹œ Excel íŒŒì¼ì— ì €ì¥
    - í…œí”Œë¦¿ ê¸°ë°˜ ì‹œíŠ¸ ìƒì„± (copy_worksheet ì‚¬ìš©)
    - ì¤‘ë³µ ì‹œíŠ¸ëª… ìë™ ì²˜ë¦¬
    """
    
    # ğŸ†• ê¸°ë³¸ í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ
    DEFAULT_TEMPLATE = "TestResult_OCR_v1.xlsx"
    
    def __init__(self, output_path="ë³´ì¡´ë ¥ì‹œí—˜_ìµœì¢….xlsx", template_file=None):
        """
        Args:
            output_path (str): ì €ì¥í•  Excel íŒŒì¼ ê²½ë¡œ
            template_file (str): í…œí”Œë¦¿ Excel íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.output_path = output_path
        
        # ğŸ†• template_fileì´ Noneì´ë©´ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        if template_file is None:
            self.template_file = self.DEFAULT_TEMPLATE
        else:
            self.template_file = template_file
        
        # ğŸ†• í…œí”Œë¦¿ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(self.template_file):
            logger.warning(f"âš ï¸ í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.template_file}")
            logger.warning("ë¹ˆ Excel íŒŒì¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
            self.template_file = None
        else:
            logger.info(f"âœ… í…œí”Œë¦¿ íŒŒì¼ í™•ì¸: {self.template_file}")
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if not os.path.exists(self.output_path):
            self._initialize_excel()
    
    def _initialize_excel(self):
        """Excel íŒŒì¼ ì´ˆê¸°í™”"""
        try:
            if self.template_file and os.path.exists(self.template_file):
                # ğŸ†• í…œí”Œë¦¿ íŒŒì¼ ì „ì²´ ë³µì‚¬
                import shutil
                shutil.copy2(self.template_file, self.output_path)
                
                # ğŸ†• ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ TEMPLATE_BASEë¡œ ì´ë¦„ ë³€ê²½
                from openpyxl import load_workbook
                workbook = load_workbook(self.output_path)
                
                if len(workbook.sheetnames) > 0:
                    first_sheet = workbook[workbook.sheetnames[0]]
                    first_sheet.title = "TEMPLATE_BASE"
                    logger.info(f"âœ… í…œí”Œë¦¿ ì‹œíŠ¸ '{workbook.sheetnames[0]}' â†’ 'TEMPLATE_BASE'ë¡œ ë³€ê²½")
                
                workbook.save(self.output_path)
                workbook.close()
                
                logger.info(f"âœ… í…œí”Œë¦¿ ê¸°ë°˜ Excel ì´ˆê¸°í™” ì™„ë£Œ: {self.output_path}")
            else:
                # ë¹ˆ Excel ìƒì„±
                wb = Workbook()
                wb.remove(wb.active)
                wb.save(self.output_path)
                wb.close()
                
                logger.warning(f"âš ï¸ í…œí”Œë¦¿ ì—†ì´ ë¹ˆ Excel íŒŒì¼ ìƒì„±: {self.output_path}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ Excel ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def add_test_data(self, test_data, date_info=None):
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ Excelì— ì¶”ê°€
        
        Args:
            test_data: DataFrame ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            date_info: ë‚ ì§œ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            from openpyxl import load_workbook
            
            # Excel íŒŒì¼ ë¡œë“œ
            workbook = load_workbook(self.output_path)
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            if isinstance(test_data, pd.DataFrame):
                df = test_data
            elif isinstance(test_data, list):
                df = pd.DataFrame(test_data)
            else:
                logger.error("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹")
                return False
            
            if df.empty:
                logger.warning("âš ï¸ ë¹ˆ ë°ì´í„° - ì €ì¥ ê±´ë„ˆë›°ê¸°")
                return False
            
            # ì‹œí—˜ë²ˆí˜¸ ì¶”ì¶œ
            test_number = df.iloc[0].get('test_number', '')
            if not test_number:
                test_number = "Unknown_Test"
                logger.warning(f"âš ï¸ ì‹œí—˜ë²ˆí˜¸ ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©: {test_number}")
            
            # ì¤‘ë³µ ì‹œíŠ¸ëª… ì²˜ë¦¬
            sheet_name = str(test_number)
            counter = 1
            original_name = sheet_name
            while sheet_name in workbook.sheetnames:
                sheet_name = f"{original_name}_{counter}"
                counter += 1
            
            # ğŸ†• í…œí”Œë¦¿ ì‹œíŠ¸ ë³µì‚¬í•˜ì—¬ ìƒˆ ì‹œíŠ¸ ìƒì„±
            if "TEMPLATE_BASE" in workbook.sheetnames:
                template_sheet = workbook["TEMPLATE_BASE"]
                new_sheet = workbook.copy_worksheet(template_sheet)
                new_sheet.title = sheet_name
                logger.info(f"âœ… í…œí”Œë¦¿ ì‹œíŠ¸ ë³µì‚¬ ì™„ë£Œ: {sheet_name}")
            else:
                # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ë¹ˆ ì‹œíŠ¸ ìƒì„±
                new_sheet = workbook.create_sheet(title=sheet_name)
                logger.warning(f"âš ï¸ í…œí”Œë¦¿ ì—†ì´ ë¹ˆ ì‹œíŠ¸ ìƒì„±: {sheet_name}")
            
            # ë°ì´í„° ë§¤í•‘
            self._map_data_to_sheet(new_sheet, df, date_info)
            
            # ì¦‰ì‹œ ì €ì¥
            workbook.save(self.output_path)
            workbook.close()
            
            logger.info(f"ğŸ’¾ Excel ì €ì¥ ì™„ë£Œ: {sheet_name} ì‹œíŠ¸ ì¶”ê°€")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Excel ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _map_data_to_sheet(self, worksheet, df, date_info):
        """ë°ì´í„°ë¥¼ ì‹œíŠ¸ì— ë§¤í•‘"""
        try:
            if df.empty:
                logger.warning("âš ï¸ ë¹ˆ DataFrame - ë§¤í•‘ ê±´ë„ˆë›°ê¸°")
                return
            
            # ì‹œí—˜ë²ˆí˜¸ ë§¤í•‘
            test_number = df.iloc[0].get('test_number', '')
            worksheet['AA3'] = test_number  # ì›ë³¸ ë³´ê³ ì„œ
            worksheet['AA33'] = test_number  # Log ë³´ê³ ì„œ
            logger.info(f"ğŸ“ ì‹œí—˜ë²ˆí˜¸ ë§¤í•‘: AA3, AA33 = {test_number}")
            
            # ì²˜ë°©ë²ˆí˜¸ ë§¤í•‘
            if 'prescription_number' in df.columns:
                prescription_number = df.iloc[0].get('prescription_number', '')
                if prescription_number:
                    worksheet['E4'] = prescription_number  # ì›ë³¸
                    worksheet['E34'] = prescription_number  # Log
                    logger.info(f"ğŸ“ ì²˜ë°©ë²ˆí˜¸ ë§¤í•‘: E4, E34 = {prescription_number}")
            
            # ë‚ ì§œ ì •ë³´ ë§¤í•‘
            if date_info:
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                if isinstance(date_info, dict):
                    date_list = [
                        date_info.get('date_0', ''),
                        date_info.get('date_7', ''),
                        date_info.get('date_14', ''),
                        date_info.get('date_28', '')
                    ]
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                elif isinstance(date_info, list):
                    date_list = date_info
                else:
                    date_list = []
                
                if len(date_list) >= 4:
                    date_positions_original = ['I19', 'L19', 'O19', 'R19']
                    date_positions_log = ['I49', 'L49', 'O49', 'R49']
                    
                    for i, date_val in enumerate(date_list[:4]):
                        if date_val:  # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ë§¤í•‘
                            worksheet[date_positions_original[i]] = date_val
                            worksheet[date_positions_log[i]] = date_val
                    
                    logger.info(f"ğŸ“… ë‚ ì§œ ì •ë³´ ë§¤í•‘: {date_list}")
            
            # ê· ì£¼ë³„ CFU ë°ì´í„° ë§¤í•‘
            strain_mapping = {
                'E.coli': 'E.coli',
                'Escherichia coli': 'E.coli',
                'P.aeruginosa': 'P.aeruginosa',
                'Pseudomonas aeruginosa': 'P.aeruginosa',
                'S.aureus': 'S.aureus',
                'Staphylococcus aureus': 'S.aureus',
                'C.albicans': 'C.albicans',
                'Candida albicans': 'C.albicans',
                'A.brasiliensis': 'A.brasiliensis',
                'Aspergillus brasiliensis': 'A.brasiliensis'
            }
            
            original_positions = {
                'E.coli': ['J20', 'M20', 'P20', 'S20', 'U20'],
                'P.aeruginosa': ['J21', 'M21', 'P21', 'S21', 'U21'],
                'S.aureus': ['J22', 'M22', 'P22', 'S22', 'U22'],
                'C.albicans': ['J23', 'M23', 'P23', 'S23', 'U23'],
                'A.brasiliensis': ['J24', 'M24', 'P24', 'S24', 'U24']
            }
            
            log_positions = {
                'E.coli': ['J50', 'M50', 'P50', 'S50'],
                'P.aeruginosa': ['J51', 'M51', 'P51', 'S51'],
                'S.aureus': ['J52', 'M52', 'P52', 'S52'],
                'C.albicans': ['J53', 'M53', 'P53', 'S53'],
                'A.brasiliensis': ['J54', 'M54', 'P54', 'S54']
            }
            
            mapped_count = 0
            for _, row in df.iterrows():
                strain = row.get('strain', '')
                if not strain:
                    continue
                
                mapped_strain = strain_mapping.get(strain, strain)
                
                if mapped_strain in original_positions:
                    # ì›ë³¸ CFU ê°’
                    positions = original_positions[mapped_strain]
                    worksheet[positions[0]] = row.get('cfu_0day', '')
                    worksheet[positions[1]] = row.get('cfu_7day', '')
                    worksheet[positions[2]] = row.get('cfu_14day', '')
                    worksheet[positions[3]] = row.get('cfu_28day', '')
                    worksheet[positions[4]] = row.get('judgment', '')
                    
                    # Log ê°’
                    log_pos = log_positions[mapped_strain]
                    worksheet[log_pos[0]] = DataCleaner.convert_to_log(row.get('cfu_0day', ''))
                    worksheet[log_pos[1]] = DataCleaner.convert_to_log(row.get('cfu_7day', ''))
                    worksheet[log_pos[2]] = DataCleaner.convert_to_log(row.get('cfu_14day', ''))
                    worksheet[log_pos[3]] = DataCleaner.convert_to_log(row.get('cfu_28day', ''))
                    
                    mapped_count += 1
                    logger.info(f"ğŸ¦  {mapped_strain} ë°ì´í„° ë§¤í•‘ ì™„ë£Œ")
            
            logger.info(f"âœ… ì´ {mapped_count}ê°œ ê· ì£¼ ë°ì´í„° ë§¤í•‘ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë§¤í•‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def get_sheet_list(self):
        """í˜„ì¬ Excel íŒŒì¼ì˜ ì‹œíŠ¸ ëª©ë¡ ë°˜í™˜"""
        try:
            from openpyxl import load_workbook
            
            if os.path.exists(self.output_path):
                workbook = load_workbook(self.output_path, read_only=True)
                sheet_names = workbook.sheetnames
                workbook.close()
                
                # TEMPLATE_BASE ì œì™¸
                filtered_names = [name for name in sheet_names if name != "TEMPLATE_BASE"]
                logger.info(f"ğŸ“‹ ì‹œíŠ¸ ëª©ë¡: {filtered_names}")
                return filtered_names
            else:
                logger.warning(f"âš ï¸ Excel íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.output_path}")
                return []
        except Exception as e:
            logger.error(f"âŒ ì‹œíŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_excel_bytes(self):
        """Excel íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ë°˜í™˜ (ë‹¤ìš´ë¡œë“œìš©)"""
        try:
            if os.path.exists(self.output_path):
                with open(self.output_path, 'rb') as f:
                    excel_bytes = f.read()
                logger.info(f"âœ… Excel íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(excel_bytes)} bytes")
                return excel_bytes
            else:
                logger.warning(f"âš ï¸ Excel íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.output_path}")
                return None
        except Exception as e:
            logger.error(f"âŒ Excel ì½ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def get_statistics(self):
        """Excel íŒŒì¼ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            from openpyxl import load_workbook
            
            if not os.path.exists(self.output_path):
                return {
                    'total_sheets': 0,
                    'test_sheets': 0,
                    'file_size': 0
                }
            
            workbook = load_workbook(self.output_path, read_only=True)
            total_sheets = len(workbook.sheetnames)
            test_sheets = len([name for name in workbook.sheetnames if name != "TEMPLATE_BASE"])
            workbook.close()
            
            file_size = os.path.getsize(self.output_path)
            
            stats = {
                'total_sheets': total_sheets,
                'test_sheets': test_sheets,
                'file_size': file_size,
                'file_size_mb': round(file_size / (1024 * 1024), 2)
            }
            
            logger.info(f"ğŸ“Š í†µê³„: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'total_sheets': 0,
                'test_sheets': 0,
                'file_size': 0
            }

# í¸ì˜ í•¨ìˆ˜
def process_pdf_page(pdf_bytes: bytes, page_index: int) -> dict:
    """PDF í˜ì´ì§€ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    result = {
        'success': False,
        'data': [],
        'date_info': {},
        'message': ''
    }
    
    try:
        # 1. ì´ë¯¸ì§€ ë Œë”ë§
        img_bytes = PDFProcessor.render_page_image(pdf_bytes, page_index)
        if not img_bytes:
            result['message'] = "ì´ë¯¸ì§€ ë Œë”ë§ ì‹¤íŒ¨"
            return result
        
        # 2. OCR ì²˜ë¦¬
        ocr_result = OCRProcessor.request_ocr(img_bytes)
        if not ocr_result:
            result['message'] = "OCR ì²˜ë¦¬ ì‹¤íŒ¨"
            return result
        
        # 3. í…Œì´ë¸” íŒŒì‹±
        table_data, date_info = OCRProcessor.parse_table_from_ocr(ocr_result)
        
        result['success'] = True
        result['data'] = table_data
        result['date_info'] = date_info
        result['message'] = f"{len(table_data)}ê°œ ê· ì£¼ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ"
        
        return result
        
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        result['message'] = str(e)
        return result